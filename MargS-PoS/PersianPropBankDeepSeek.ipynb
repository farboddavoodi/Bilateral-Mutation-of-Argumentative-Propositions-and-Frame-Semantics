{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5HMFUDMv9qL"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8X7a4Cpvxgt"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iTNZe29yjw7"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install unsloth\n",
        "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git@nightly git+https://github.com/unslothai/unsloth-zoo.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_6Wh7D8Lw8m"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTmu0_PRv9uH"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -U transformers peft accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruFzPMB2y6XJ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29 peft trl triton\n",
        "    !pip install --no-deps cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "    !pip install --no-deps unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh7irNCFJBzi",
        "outputId": "3b1d9740-afbe-4a26-8ca4-9d0e18a53869"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePHE1bKg50yU",
        "outputId": "0641b8ce-8f41-4b7a-eaaa-71b56feaa240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['README.md', 'adapter_model.safetensors', 'tokenizer.json', 'tokenizer_config.json', 'adapter_config.json', 'special_tokens_map.json']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "lora_path = \"/content/drive/MyDrive/English_SRL_unsloth_Llama-3.2-3B-Instruct-bnb-4bit/lora/\"\n",
        "print(os.listdir(lora_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l7szMYFD8AF",
        "outputId": "8d611779-5d32-46b6-f6ba-6f5e9354fa69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 2.5.1+cu121 with CUDA 1201 (you have 2.6.0+cu124)\n",
            "    Python  3.11.11 (you have 3.11.11)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "from unsloth import is_bfloat16_supported\n",
        "from trl import SFTTrainer\n",
        "import torch\n",
        "import pandas as pd\n",
        "import ast\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import Trainer, TrainingArguments, BatchEncoding#AdamW, get_linear_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExLj7VvND79D"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\")\n",
        "json_data = '/content/drive/MyDrive/davodi.json'\n",
        "persian_df = pd.read_json(json_data)\n",
        "persian_df = persian_df.drop(['_id', 'sentence', 'frame', 'lexicalUnit', 'status', 'issuer', 'is_active', 'createdAt', 'updatedAt', 'PId', 'lang', 'description', 'lexicalUnitHint', 'reviewer', 'lexicalUnitHelper', 'frameHelper', 'frameName', 'lexicalUnitName'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snOJ5yhBQIzx"
      },
      "outputs": [],
      "source": [
        "def framenet_tags(FN_tags):\n",
        "    framenet_pattern = []\n",
        "    for FN_tag in FN_tags:\n",
        "        tag_type = FN_tag.get('tagType')\n",
        "        if tag_type == 5:\n",
        "            element = FN_tag.get('element', {})\n",
        "            element_name = element.get('name', '')\n",
        "            framenet_pattern.append(element_name)\n",
        "        else:\n",
        "            framenet_pattern.append('O')\n",
        "    return framenet_pattern"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHlhIPT8QI4U"
      },
      "outputs": [],
      "source": [
        "persian_df['frameNetTags'] = persian_df['frameNetTags'].apply(lambda FN_tags : framenet_tags(FN_tags))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-UwLI3LckVW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "torch.cuda.empty_cache()\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ghf_2UWxcCkd"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "from datasets import load_dataset, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "persian_df_tr, persian_df_temp = train_test_split(persian_df, random_state=seed, test_size=.08)\n",
        "persian_df_val, persian_df_te = train_test_split(persian_df_temp, random_state=seed, test_size=.05)\n",
        "del persian_df_temp\n",
        "persian_df_tr.reset_index(drop=True, inplace=True)\n",
        "persian_df_val.reset_index(drop=True, inplace=True)\n",
        "persian_df_te.reset_index(drop=True, inplace=True)\n",
        "persian_df_tr = Dataset.from_pandas(persian_df_tr)\n",
        "persian_df_val = Dataset.from_pandas(persian_df_val)\n",
        "persian_df_te = Dataset.from_pandas(persian_df_te)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rw3dKfXadGXZ"
      },
      "outputs": [],
      "source": [
        "prop_prompt_template = \"\"\"<|start_header_id|>system<|end_header_id|>\n",
        "Please generate PropBank roles for the provided text.\n",
        "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "You are an expert in the field of Semantic Role Labeling and lexical resources especially PropBank.\n",
        "You know anything about how to label sentence tokens with PropBank roles.\n",
        "Please use the following text:\"+ {}+\"Here are the propbank roles you have to use for labeling:\" + {}+\"\n",
        "Your task is to generate PropBank roles for the provided text.\n",
        "The output should be a list of roles in a list format. IF a token does not have any role, put 'O'.\n",
        "Make sure that you do NOT use any roles other than the ones I provided in this prompt.\n",
        "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "{}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340,
          "referenced_widgets": [
            "8938632837ae44478d157868ce630141",
            "8edcae2272f54b4a83f37a1f2705bab6",
            "e34acb38a9c842b78e3066863b50eb9f",
            "51ab8d35263049c78083229dbcb0dd56",
            "f48da4061d58480183e7a2e6f73834e1",
            "47522075a5294474a98025b01a242157",
            "1e8a3ae8af5c4f3d8cb012d71c2392cc",
            "4491609f2f7041478b5ef4d817fa9838",
            "2e40408a33f54b048fc502b8f1c34875",
            "ae66cfa0cb8043da967abf238e57bc65",
            "660b6259fc214b1b817d6406e087f5b9",
            "5b5203ae50244cb9ad7b3fab9960c25a",
            "2a53d5b09bbb4f9981e1e06aa05cf280",
            "d4a51d63ae674dbcaf48e67708d4cc24",
            "ca2db8c5b1ef46d0a6226cfc16fcb5cb",
            "91220af2e9144bc9b31f5782e2043ecf",
            "dfcfaa7ac0f345649cfff01013c62b46",
            "8c467a269b114e58a96cf4f44ea89291",
            "fdadcd2ea1644c24a00f8356d8e63c1c",
            "74505169f210401c8eaf9c4b4806d074",
            "12135bb14e0247a49aa5b255740ad753",
            "667fba1657cd47d8939df13d316d5ee2",
            "39c1060ccdc74264862139a49cd2cf43",
            "e402fabaa9c0444eb21fe784614c66b4",
            "0f2dca32e7f3471ea22134088448ab34",
            "f29fb1d9250943e0b15b952006d90d8b",
            "23730f56c4d84a74bdc5e717865be3f1",
            "0cb778ffc6b74fb8a924545da298f615",
            "433bfaab821d4d7cbacd51d2de1ea3d9",
            "166e97f686db471e9d942e57f40efd5f",
            "9cbe3be395d84a75886bab175efcd014",
            "addefea55e6f4bf392c8c5cd74addb26",
            "a41e0abd272c412fbba8fc973d0a303d",
            "a348cabf84a147b682cbdae0ccc233c9",
            "55c723b923e3424a87cc2c5ff6955cb4",
            "5c8f050ce8634f1b85cc1d6bb63041f8",
            "3adee4726bbb4f038ac896c6898284cc",
            "022d0767dbbe4168b0693a578d226d6e",
            "3fd26b2203c44fe0933dd67bbdd53987",
            "aa1d4aea865e4f7d95d0882e2ee7135c",
            "7e6e8fce817b4a6980854b3d63c46e4a",
            "511419cbc3a0476b87f057cb9d352f2c",
            "a6c19082f7374074890d1ab5169bfb34",
            "9f4c8a21fb16480385f2f6dc6409d219",
            "5868ca7f26254084b947d141fc5b1963",
            "c5dbb9febbb845ae8f209ac2995ae638",
            "907064edefb34124a5d56e7030f7f918",
            "1d7f918fd66a4dd48934ee8b13d5f04e",
            "d018c8188e054f9ab51bd192cd58230e",
            "58b5307d83ae4a7d9e742a8b87a65552",
            "4453c439b9eb448bb922ee244593de31",
            "18038738991044f3b1266b0e8ed9f92b",
            "ccc56923c5b9424583075e571aad46e9",
            "ef7bef268837429cad8c01446e7958d2",
            "9e1ac9a29bd043c686be1e8315409af4",
            "60fbc9c417ae46159f76b77fed84d414",
            "2863ecbd78c44141941dc0b18f98ca46",
            "57b98d1acfd743cea0562eb579da0d5f",
            "990e2c77af0c40f09ef8610f1744ab08",
            "699ede907424463dbea75946845fb1a2",
            "22d78fe041fc4f9cb3a7d7203d70d2f4",
            "78aa3337eee641c9b9b5c6898efea4e9",
            "9c4d8a8b1b534da589b7ca984e4e281a",
            "6748de89c70947a88f8e39b3426e2f50",
            "763f9e98d5574300a6e45ad78e5126b9",
            "da0843263fc64bf89ece9449fde17948",
            "b1451e64e06f47908fd4c22df735c49a",
            "d7b760bdada84e47999ee1ffc8d16e7f",
            "1c12b4e8725140b88517032362758958",
            "8724d9c3210149cabd1afd60c6ee7d1f",
            "b7f511e3c6d847408108dbc99e07f143",
            "ef6611952c5b41d6bc5f2497f706e772",
            "684ffa991c2444189566bd68b8a5bd0f",
            "9df7222cdb124a4c847a9ed1e8b0dccf",
            "f3fb150852d0418399ab086d1fe22b5f",
            "62c70ba0642847bbbdd4bbce82c57391",
            "18e3fad3569449e0bcbf5129d2b03327",
            "5db9557b89b04e60aa3098a89ca79286",
            "49c1ce5889de4f86b8fa9fad84114989",
            "c56464529e344dcab19073eaec575fae",
            "c78960f59d714a02ba6aae74a8ac2085",
            "94b586f5daa04dccac4c264afaf9f0b5",
            "632d322cb5e54f68ae5243887f51ce87",
            "4b950221d100457d81d0641742969f11",
            "d5f2a967be4144a3b491e994aee2c186",
            "30f7d40f25e2416bb9052a29b7e19bf8",
            "6a0f05a0b59e48a28cbb67d838a3d627",
            "d9858de0508749ce93c323a9d2267094",
            "a3f669f0c73f40269977f14060c94e0d",
            "0fc62bac915b47988d104de950647224",
            "962a32b5913b413fadb8217d0e9f76ed",
            "44cb7a9c6c8d488eac395ef0984b32f9",
            "93458be8552141669ee54cd3695555a2",
            "3a0114bf1d714e2ab7f8c7c9c3c6ca1e",
            "1e82a1aff58f4ee585d0fdee978d9004",
            "f32c32ff082a484dbe849e52568fdedc",
            "a450519becee480098d1524b161a68b6",
            "0e4c374f724a4b94b5dbf4ff63005c46",
            "8cb32a668dd24c9fab972d88b5b14d07"
          ]
        },
        "id": "dM2xsAI7D8Dg",
        "outputId": "7fdf2779-a912-4a1b-f238-ba097140b793"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8938632837ae44478d157868ce630141",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/792 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b5203ae50244cb9ad7b3fab9960c25a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/4.61M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39c1060ccdc74264862139a49cd2cf43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/584 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a348cabf84a147b682cbdae0ccc233c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin.index.json:   0%|          | 0.00/22.5k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5868ca7f26254084b947d141fc5b1963",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.97G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60fbc9c417ae46159f76b77fed84d414",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1451e64e06f47908fd4c22df735c49a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5db9557b89b04e60aa3098a89ca79286",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3f669f0c73f40269977f14060c94e0d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/121 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 3,932,160 || all params: 6,914,297,856 || trainable%: 0.0569\n",
            "âœ… DeepSeek LLM Loaded with LoRA and 4-bit Precision!\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model\n",
        "model_name = \"deepseek-ai/deepseek-llm-7b-base\"\n",
        "bnb_config = BitsAndBytesConfig(load_in_4bit=True,bnb_4bit_compute_dtype=torch.float16)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name,quantization_config=bnb_config,device_map=\"auto\")\n",
        "lora_config = LoraConfig(r=8,lora_alpha=32,target_modules=[\"q_proj\", \"v_proj\"],lora_dropout=0.05,bias=\"none\")\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()\n",
        "print(\"âœ… DeepSeek LLM Loaded with LoRA and 4-bit Precision!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252,
          "referenced_widgets": [
            "9f097185a77b41c9b5638815280fc335",
            "9ff995deac7e457c8eb00a606a6401fc",
            "0a93c5dafad6445bab3d37bcc2742ab4",
            "ad250208f70d4500a2f35e42ecfebdb3",
            "3a1793c493eb420c82f33022d1e8d761",
            "0f62f9061cd54747a053efe80a917e17",
            "d7ebff6fcbbf483ab0e97e54784f58f0",
            "cc0757e884dc4a87837c8123d42b36b2",
            "f014de0bd8ff409f97c7f7d63dbb2afb",
            "3b7fee0795d64c8d8824671a049ba343",
            "51c59ba2b6b649a0bc547580077dd501",
            "cc1c549f18484d2387e3c7096a336274",
            "98d95274404d45f6b07c1b161d0740f8",
            "7e06ae4068d7468cba761f52e4193e0b",
            "e0fa1859a08c4c418b9358f0b946b79a",
            "1c3ed77a6eb24c5985200b74c4b1062c",
            "8c180e29913642c28d4ee6c38832c9fa",
            "8648d8f5644344968ebd7f093cdd0e8d",
            "09a0f102d3634d7aa9964ebbd82f2c28",
            "44e1377ab2f74f558ed145c3f8d0df63",
            "4a324ee1051242638c530530d902cdf5",
            "44b7366ef55a4d73b947c8a6e5496704",
            "b5724c01a4d84869893bbccb507bc89d",
            "dcecb13c1fbf4bc68edff2b245ef8b63",
            "5e5c8bb598f04893b45099656114586a",
            "571c228b7c5e4ef9ae26b04684317851",
            "7e0c980538cc428ea1e2af15ffaa7fb3",
            "9ee3309270fb4792b84257a78f04eee2",
            "eb1d4844992e4a6e9b24d4ac35232398",
            "135db615dc134b7db2b0cf3dc1f01786",
            "c5d8b0eaf4064b898f499be74d6327a0",
            "ff20e2c55ed947ea800528ea691ac442",
            "9a633ee0d16f4c58b4b9e5a1d254d78c"
          ]
        },
        "id": "_MFN4TOXDA8r",
        "outputId": "5baa13c0-7e87-42ac-a98e-e95d079c482d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f097185a77b41c9b5638815280fc335",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc1c549f18484d2387e3c7096a336274",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/792 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5724c01a4d84869893bbccb507bc89d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/4.61M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "deepseek-ai/deepseek-llm-7b-base does not have a padding token! Will use pad_token = <|PAD_TOKEN|>.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2025.3.19 patched 30 layers with 30 QKV layers, 30 O layers and 30 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(model_name = model_name, max_seq_length = 2048,dtype = None,load_in_4bit = True,)\n",
        "model = FastLanguageModel.get_peft_model(model,r=16,\n",
        "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\",],\n",
        "    lora_alpha=16,lora_dropout=0,bias=\"none\",use_gradient_checkpointing=\"unsloth\",random_state=3407,use_rslora=False,loftq_config=None,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6FsOt4HOibM"
      },
      "outputs": [],
      "source": [
        "EOS_TOKEN = tokenizer.eos_token\n",
        "def formatting_prompts_function(examples):\n",
        "    words = examples[\"words\"]\n",
        "    props = examples[\"propBankTags\"]\n",
        "    texts = []\n",
        "    for word, prop in zip(words, props):\n",
        "        text = prop_prompt_template.format(word, str(prop_roles), prop) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return tokenizer(examples[\"words\"],padding=True,truncation=True,return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfTmhsBtdU0e"
      },
      "outputs": [],
      "source": [
        "prop_roles = set()\n",
        "for _, row in persian_df.iterrows():\n",
        "    prop_str = ast.literal_eval(str(row['propBankTags']))\n",
        "    prop_roles.update(prop_str)\n",
        "prop_roles = list(prop_roles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "fbc750a164dc4e3bbcc604cbc11e948e",
            "9f8c947f6eaf472e9e3d6c3fe1cd731c",
            "5ef1ce4e0b6247a692fed0c5e213cf59",
            "033b8332a6dc41838a39dba906fcb52b",
            "f7576716b8314c9188aad35b91616f63",
            "e68e2b24843d48bcb290c5f75521145c",
            "deadd9a55b4f4930a6b93a9ef226cf6b",
            "8eb3b22bd48f42cdbebdebe473e9b512",
            "060cc7e1765f4452b31681ed4a14b70b",
            "52e21c001bc548b198f83570cab33536",
            "625b74273ff0481395af74408a0685cb",
            "fbbbae8add004e1888ffd659a34c283d",
            "cc785739414c43c6b94389fe6d8ab084",
            "c825566c06a64cfeaf26bce3e671aabf",
            "03af9452230c4b23a5f3aa916eef706c",
            "8ba5f4c0e29f4173969fcef7d8ea9ff3",
            "38492f411b0143a6aa8286b63e54ff73",
            "a68e7b3f67784350b3babe1bd203dd5f",
            "e943fb6087f44d13b3afb09647e073df",
            "7ce37b2207cd443c8de9aa5f2f086c7b",
            "d5c17d6c7d9b4751828812267bfc976a",
            "84754d82a06249619b4383a17bb1cecc",
            "f1eb63434f094d3a91bfaedc926ec25b",
            "fa6255c4f8524819a97864c3351ad5e9",
            "7d9d89c5b14e4658869275982f39caa3",
            "ce3dfe6a1418482c95b3988118dd6889",
            "49918e4649fc4ad888e56184e24db2de",
            "4d4c89d3d32c450d905f0502a748d909",
            "4f5332fdd2ba42768f2e4d9c11a8ac0d",
            "eb48d108a7f74121b4b5d920965aa5c3",
            "182c41f3bab04eea8e3deab9c3984cb0",
            "50481c667d904244ab577587eb6bd934",
            "d7f922b4b4eb413b93e8ea70458af3d7"
          ]
        },
        "id": "frNuhGSDb28v",
        "outputId": "b4ff5844-9db0-4991-b36a-62806b9bd073"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbc750a164dc4e3bbcc604cbc11e948e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/92 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbbbae8add004e1888ffd659a34c283d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1eb63434f094d3a91bfaedc926ec25b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "main_dataset = persian_df_tr.map(formatting_prompts_function, remove_columns=persian_df_tr.column_names, batched=True)#, num_proc=1\n",
        "eval_dataset = persian_df_val.map(formatting_prompts_function, remove_columns=persian_df_val.column_names, batched=True)\n",
        "test_dataset = persian_df_te.map(formatting_prompts_function, remove_columns=persian_df_te.column_names, batched=True)\n",
        "\n",
        "main_dataset = main_dataset.shuffle(seed=seed)\n",
        "eval_dataset = eval_dataset.shuffle(seed=seed)\n",
        "test_dataset = test_dataset.shuffle(seed=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaFAUNippYMp",
        "outputId": "c488c9bf-0b8d-4d98-d7f7-04f5d6f2d30c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: os.environ[CUDA_VISIBLE_DEVICES]: command not found\n"
          ]
        }
      ],
      "source": [
        "!os.environ['CUDA_VISIBLE_DEVICES'] ='0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQvF9J1ZvS7Z"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from evaluate import load\n",
        "import numpy as np\n",
        "import math\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = logits.argmax(axis=-1)\n",
        "    labels = torch.tensor(labels, dtype=torch.int32)\n",
        "    print(\"Predictions:\", predictions.shape)\n",
        "    print(\"Labels:\", labels.shape)\n",
        "    results = {}\n",
        "    def compute_token_accuracy(predicted_ids, label_ids):\n",
        "        total_tokens = 0\n",
        "        correct_tokens = 0\n",
        "        for pred, ref in zip(predicted_ids, label_ids):\n",
        "            for p_token, r_token in zip(pred, ref):\n",
        "                if r_token != -100:\n",
        "                    total_tokens += 1\n",
        "                    if p_token == r_token:\n",
        "                        correct_tokens += 1\n",
        "        return (correct_tokens / total_tokens) * 100 if total_tokens > 0 else 0.0\n",
        "    if labels is not None:\n",
        "        logits_tensor = torch.tensor(logits, dtype=torch.float32)\n",
        "        labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
        "        per_sample_losses = []\n",
        "        for sample_logits, sample_labels in zip(logits_tensor, labels_tensor):\n",
        "            loss = F.cross_entropy(sample_logits.view(-1, sample_logits.size(-1)),sample_labels.view(-1),reduction=\"none\")\n",
        "            per_sample_loss = loss.view(sample_labels.size(0), -1).mean(dim=1).mean().item()\n",
        "            per_sample_losses.append(per_sample_loss)\n",
        "        results[\"manual_eval_loss\"] = sum(per_sample_losses) / len(per_sample_losses)\n",
        "        results[\"perplexity\"] = math.exp(results[\"manual_eval_loss\"])\n",
        "        results[\"loss_per_sample\"] = per_sample_losses\n",
        "\n",
        "    # 2. Token-Level Metrics\n",
        "    if labels is not None:\n",
        "        flattened_preds = []\n",
        "        flattened_labels = []\n",
        "        for pred, label in zip(predictions, labels):\n",
        "            for p_token, l_token in zip(pred, label):\n",
        "                if l_token != -100:\n",
        "                    flattened_preds.append(p_token)\n",
        "                    flattened_labels.append(l_token)\n",
        "\n",
        "        if flattened_labels and flattened_preds:\n",
        "            results[\"accuracy_score\"] = accuracy_score(flattened_labels, flattened_preds)\n",
        "            results[\"token_accuracy\"] = compute_token_accuracy(predictions, labels)\n",
        "            results[\"precision\"] = precision_score(flattened_labels, flattened_preds, average=\"macro\")\n",
        "            results[\"recall\"] = recall_score(flattened_labels, flattened_preds, average=\"macro\")\n",
        "            results[\"f1\"] = f1_score(flattened_labels, flattened_preds, average=\"macro\")\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8AJb-Yayxec"
      },
      "outputs": [],
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=main_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    dataset_num_proc=2,\n",
        "    packing=False,\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=6,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=5,\n",
        "        num_train_epochs=1,\n",
        "        learning_rate=2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        logging_strategy=\"steps\",\n",
        "        logging_steps=1,\n",
        "    ),\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YE6DjpzU7FqJ"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_zHKpZb3KzN"
      },
      "outputs": [],
      "source": [
        "eval_results = trainer.evaluate()\n",
        "print(eval_results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}