{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B5HMFUDMv9qL"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8X7a4Cpvxgt"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iTNZe29yjw7"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install unsloth\n",
        "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git@nightly git+https://github.com/unslothai/unsloth-zoo.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_6Wh7D8Lw8m"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTmu0_PRv9uH"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -U transformers peft accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruFzPMB2y6XJ"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29 peft trl triton\n",
        "    !pip install --no-deps cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "    !pip install --no-deps unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qh7irNCFJBzi",
        "outputId": "246306f6-d198-4442-f83a-0c5766d0afb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePHE1bKg50yU",
        "outputId": "36752d88-3cf8-433f-95c8-e9a6eb17abda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['README.md', 'adapter_model.safetensors', 'tokenizer.json', 'tokenizer_config.json', 'adapter_config.json', 'special_tokens_map.json']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "lora_path = \"/content/drive/MyDrive/English_SRL_unsloth_Llama-3.2-3B-Instruct-bnb-4bit/lora/\"\n",
        "print(os.listdir(lora_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l7szMYFD8AF",
        "outputId": "892f4261-0dc8-4fd0-c5aa-c9259e1dd03a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 2.5.1+cu121 with CUDA 1201 (you have 2.6.0+cu124)\n",
            "    Python  3.11.11 (you have 3.11.11)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "from unsloth import is_bfloat16_supported\n",
        "from trl import SFTTrainer\n",
        "import torch\n",
        "import pandas as pd\n",
        "import ast\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import Trainer, TrainingArguments, BatchEncoding#AdamW, get_linear_schedule_with_warmup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ExLj7VvND79D"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\")\n",
        "json_data = '/content/drive/MyDrive/davodi.json'\n",
        "persian_df = pd.read_json(json_data)\n",
        "persian_df = persian_df.drop(['_id', 'sentence', 'frame', 'lexicalUnit', 'status', 'issuer', 'is_active', 'createdAt', 'updatedAt', 'PId', 'lang', 'description', 'lexicalUnitHint', 'reviewer', 'lexicalUnitHelper', 'frameHelper', 'frameName', 'lexicalUnitName'], axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snOJ5yhBQIzx"
      },
      "outputs": [],
      "source": [
        "def framenet_tags(FN_tags):\n",
        "    framenet_pattern = []\n",
        "    for FN_tag in FN_tags:\n",
        "        tag_type = FN_tag.get('tagType')\n",
        "        if tag_type == 5:\n",
        "            element = FN_tag.get('element', {})\n",
        "            element_name = element.get('name', '')\n",
        "            framenet_pattern.append(element_name)\n",
        "        else:\n",
        "            framenet_pattern.append('O')\n",
        "    return framenet_pattern"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHlhIPT8QI4U"
      },
      "outputs": [],
      "source": [
        "persian_df['frameNetTags'] = persian_df['frameNetTags'].apply(lambda FN_tags : framenet_tags(FN_tags))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-UwLI3LckVW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "torch.cuda.empty_cache()\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ghf_2UWxcCkd"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "from datasets import load_dataset, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "persian_df_tr, persian_df_temp = train_test_split(persian_df, random_state=seed, test_size=.08)\n",
        "persian_df_val, persian_df_te = train_test_split(persian_df_temp, random_state=seed, test_size=.05)\n",
        "del persian_df_temp\n",
        "persian_df_tr.reset_index(drop=True, inplace=True)\n",
        "persian_df_val.reset_index(drop=True, inplace=True)\n",
        "persian_df_te.reset_index(drop=True, inplace=True)\n",
        "persian_df_tr = Dataset.from_pandas(persian_df_tr)\n",
        "persian_df_val = Dataset.from_pandas(persian_df_val)\n",
        "persian_df_te = Dataset.from_pandas(persian_df_te)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rw3dKfXadGXZ"
      },
      "outputs": [],
      "source": [
        "frame_prompt_template = \"\"\"<|start_header_id|>system<|end_header_id|>\n",
        "Please generate FrameNet roles for the provided text.\n",
        "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "You are an expert in the field of Semantic Role Labeling and lexical resources especially FrameNet.\n",
        "You know anything about how to label sentence tokens with FrameNet frame elements.\n",
        "Please use the following text:\"+ {}+\"Here are the frame elements you have to use for labeling:\" + {}+\"\n",
        "Your task is to generate frame elements for the provided text.\n",
        "The output should be a list of frame elements in a list format. IF the token do not have any frame element, put 'O'.\n",
        "Make sure that you do NOT use any elements other than the ones I provided in this prompt.\n",
        "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "{}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340,
          "referenced_widgets": [
            "7cc1907370a94c0588dde5fdda7305e1",
            "370ee7ed5b5d43ea8918ea6cb5f577ac",
            "e5393adda20a4277b56cc10a7e4acdc8",
            "fb9db8ee68c54dc2947162b8ee2a5bee",
            "f015b6d8a564444892f63138ced624b4",
            "ec904d029f054ff3bd49105bcbf3858f",
            "bc1c7b436b74428998b61dcc473e8fae",
            "82d63afca46146a79434bdbaf5e5acac",
            "f6e72b61d82c4f53a6b35d6f3584fa45",
            "e3f3fb36a851438baea03b73a0e79852",
            "f8d022682d1243e18ffff5d0c1e11240",
            "d94ce2b4a7f646eba71d4057270b98af",
            "1237158d12064e1e8fff701e2b35f7f3",
            "d578d030d5d644ad99977926f48daebd",
            "47d340793fbd46f198221871b60750eb",
            "b137f8a821004aa88efd21e96ce729d7",
            "fc7bbfa3652a493398d037612797c1f6",
            "f359d92b3d454e1481403d9f05fecfae",
            "6473f66cd2714418833a31450a2afbdb",
            "5ae29c9357b8465b8df3458072dcfc2b",
            "68722e914e9846ef8621e7299fa22b45",
            "9f5263ec0f3d4860876375d610eebe5a",
            "57bd4c11020547de83ef8cc5c2e5970a",
            "5fecc253282f4c4cb57304c5201e055b",
            "b6859cdcf57a48e29c57dd3371f6e5ee",
            "1f755b4f69234355bdf3e80b97f4a622",
            "67c36eb5e4754a3fb0a31872e65c7b2e",
            "17ad896e9c444218843e4c7c5154d2c4",
            "f323767469e34b00abb811ad5957710b",
            "f9f9728afd4444daafe19af31a113367",
            "8613a6399dee47ccae03d7c0587cd1b6",
            "6f064408436a42aea0903bd11762446f",
            "a4f3d34b30eb4c61bdfdd67839dcfc21",
            "5a0d1d16adf64326bac375c00d53d1c5",
            "3d544bbd818d42048caa486414cb73eb",
            "50c58836acaf4b05b6117209e8829f8c",
            "89b97b3b8bc34b809fc11d04a6c49d3e",
            "222eaf42a74f411096ae3575bde10476",
            "d203e198dd854441bff98fa5d0bc4777",
            "6e8b2d1a029d4348878224b1c6e0dfbb",
            "1e60557db381483ba82ea1d9ae9d8b5d",
            "42245a82db2941479d14112df38d0267",
            "0e44461de3cd4962bfca755f48949d72",
            "3f06acde95e742e780729df387de5f06",
            "1c4a24e688c54204a4e82498098042de",
            "53f222dae27746a8aeb1adb5a2feeed7",
            "ffb6faf81c0d4ab38385f815f1711a95",
            "75fd32d9b3da40a28eaf44da191e1955",
            "20a22ad3149945e3840057a0b523dad9",
            "64896cca935c4ac3910683c88595481c",
            "7bb5f6a6fdff47d39c34182840f8451d",
            "8453d317940d45789ef8fce0b2ff6398",
            "19b4308a7b6f4de7a3c7ea0411bca5f8",
            "d6c334dfc62443dc9622fae9dd76393c",
            "51111cb295d6401c9551ad3a67a9b866",
            "5d7861927d854a0ca1eb65ffc8dffb9b",
            "6287f4922b4944e187a6187ce5003485",
            "a69369b92bcb4300a369da73a5a065fc",
            "d69cb6546bd4451185ebecd785850d42",
            "b76934df1b514764a0b31c43e5b0bb64",
            "ad9d247d8bde46039e481342eedcd3ec",
            "ecf7b7426c4c4a05a963611f8c166a7d",
            "493298d5e2bd4dffb075f08b4266b39e",
            "e6100d396a3f499997dda652cdb998bd",
            "38afdcd85c8e45a39caa64bc96443cf9",
            "6b387139aced43789ffa6f29df2b48e9",
            "d54a08cc5ab34c26950b9a11f8ddcfa2",
            "f4072db3bf214d1693968338d66d7442",
            "13cc5897295143bbbc497640d9254505",
            "b901b51ed274434888fa054af26808e5",
            "6e17eb8f9bb74529b25f89b3703dc551",
            "1c39d3de40aa41fc8574583f90689128",
            "b6b68b4e3f28458b9e8b9c3833af4133",
            "080cba75f8014caebc3d8242b39d34c4",
            "361cf07a31f843b592ed4b8e698d3f4c",
            "511f049c549d4fbf9a9f8624bc889bb3",
            "7f4fe8a5dedf48a098f7fce45831201f",
            "318514ab40d344379317849059de6dab",
            "c0c9d80de39e4f219a659242cd86d169",
            "dd4cee41b587415cab53167b21a47055",
            "b791de971c69434fafb48cc29f0fc84d",
            "f1d54eb90af44f158fe000180cb74297",
            "82ddcc5358dd47ee89f442db34832f4b",
            "2bb7e53cd6e4494bbacc4eaf6655710f",
            "773eaa0cb9214448b46f491b1fcbb9fe",
            "e6a73fe780c24ebf812bb58753d8889c",
            "669b1841e6b4479786312b57fc293502",
            "2bffcb4cb1e1460e92003ba751988cb5",
            "ae5f5d0bb97847c19ef5f109ff0fc7f0",
            "a76b55a2c2454f20a9aea4d62e798c61",
            "109cab99ef214253bf1a6f0f36596532",
            "f3dc3faef6c14109b3e0df910ee26624",
            "2c664b8a18704d9d8306d31d8ffc8753",
            "b4c4596c868c474187577a39100201b3",
            "ee885dcb957844a583fe1ae0ecffbf85",
            "07aa7fd912d24bb7b57ba6d0115f3690",
            "9ac96468d74b47908d57e2943fac7da9",
            "5cc158ee398842338bbb70c28ab8c606",
            "2e32ea25959c43dba6fd41002383b053"
          ]
        },
        "id": "dM2xsAI7D8Dg",
        "outputId": "01194907-ac22-422d-a540-0a3cda990833"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7cc1907370a94c0588dde5fdda7305e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/792 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d94ce2b4a7f646eba71d4057270b98af",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/4.61M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57bd4c11020547de83ef8cc5c2e5970a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/584 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a0d1d16adf64326bac375c00d53d1c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin.index.json:   0%|          | 0.00/22.5k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c4a24e688c54204a4e82498098042de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.97G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d7861927d854a0ca1eb65ffc8dffb9b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/23.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d54a08cc5ab34c26950b9a11f8ddcfa2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.85G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "318514ab40d344379317849059de6dab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae5f5d0bb97847c19ef5f109ff0fc7f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/121 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 3,932,160 || all params: 6,914,297,856 || trainable%: 0.0569\n",
            "âœ… DeepSeek LLM Loaded with LoRA and 4-bit Precision!\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model\n",
        "model_name = \"deepseek-ai/deepseek-llm-7b-base\"\n",
        "bnb_config = BitsAndBytesConfig(load_in_4bit=True,bnb_4bit_compute_dtype=torch.float16)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name,quantization_config=bnb_config,device_map=\"auto\")\n",
        "lora_config = LoraConfig(r=8,lora_alpha=32,target_modules=[\"q_proj\", \"v_proj\"],lora_dropout=0.05,bias=\"none\")\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()\n",
        "print(\"âœ… DeepSeek LLM Loaded with LoRA and 4-bit Precision!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252,
          "referenced_widgets": [
            "417cb35a90ca406e9b6ebf09a2ed2f45",
            "81f450c944ba4b9e94e299e330fbce43",
            "25393f1e43bd4291a432760521d411ca",
            "403419753eb241f491ad46fd65961c2d",
            "e132337148f842de8bac59fbc915f917",
            "d4026724d8c7489eb8f8ad712f4bcc73",
            "406374afd1c54729a4855b1dff338179",
            "f4ebe26cf5e14e2d86aa7c641a09df45",
            "f1d53b26d2484c45bd31ce482c401357",
            "462251fccea14199b38d75fa4caea0a4",
            "d0c6764884a341afa790bd3376412b72",
            "3ff8e911504d4cfeb7787055d88cb20b",
            "b52cbf61b78548f4873e38179d20a474",
            "04711238b0b64fffbf09ce34a00f745c",
            "d10e65d4bb9648c19e0b94ca6e87d788",
            "f8429cc10d51449798a680ab51b768c5",
            "966cd56d954e46e1af246c48400617af",
            "382ace95f165478e89eecd6bc5f7aa7e",
            "fc535716dea34697b397147b1f6f9b2f",
            "6378195955f8463f83dbeab2524d1dc9",
            "60aa5aebcd304738b5d6e4269163c896",
            "f1e0ea89e38746938918e1f4a2f4376e",
            "94d8ecadc24744c9952c4efb9c8c57a5",
            "c1ee1783cf444db3be845eba4499a699",
            "6c742ca63b544f41987839b1f240eaf3",
            "457c56b0cfac4b93924e800a9712ce49",
            "968efdc4b7194a0c92993a0d62f36338",
            "db42f49785264ab48ec52e3f2c57f489",
            "e3a5fcfd3c6c499e89f5bd89962a5b7c",
            "8eb0aea8a85c42b29ac6e8adb7ed9090",
            "c93f9115cf244bf5a618cfbb6827c09c",
            "8fe3894ad61146fab094ebc55edc4ae5",
            "037dd0368f694deda786b3e7249d8a2d"
          ]
        },
        "id": "_MFN4TOXDA8r",
        "outputId": "2a2363e1-3df3-4e22-9907-27b1c78721d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.50.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "417cb35a90ca406e9b6ebf09a2ed2f45",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ff8e911504d4cfeb7787055d88cb20b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/792 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94d8ecadc24744c9952c4efb9c8c57a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/4.61M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "deepseek-ai/deepseek-llm-7b-base does not have a padding token! Will use pad_token = <|PAD_TOKEN|>.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2025.3.19 patched 30 layers with 30 QKV layers, 30 O layers and 30 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(model_name = model_name, max_seq_length = 2048,dtype = None,load_in_4bit = True,)\n",
        "model = FastLanguageModel.get_peft_model(model,r=16,\n",
        "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\",],\n",
        "    lora_alpha=16,lora_dropout=0,bias=\"none\",use_gradient_checkpointing=\"unsloth\",random_state=3407,use_rslora=False,loftq_config=None,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6FsOt4HOibM"
      },
      "outputs": [],
      "source": [
        "EOS_TOKEN = tokenizer.eos_token\n",
        "def formatting_prompts_function(examples):\n",
        "    words = examples[\"words\"]\n",
        "    frams = examples[\"frameNetTags\"]\n",
        "    texts = []\n",
        "    for word, fram in zip(words, frams):\n",
        "        text = frame_prompt_template.format(word, str(frame_roles), fram) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return tokenizer(examples[\"words\"],padding=True,truncation=True,return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JfTmhsBtdU0e"
      },
      "outputs": [],
      "source": [
        "frame_roles = set()\n",
        "for _, row in persian_df.iterrows():\n",
        "    framenet_str = ast.literal_eval(str(row['frameNetTags']))\n",
        "    frame_roles.update(framenet_str)\n",
        "frame_roles = list(frame_roles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "3d5e22eae172408d8f5b568880274bd1",
            "1153a95514ea4c4696d4ba72fd2ab8bd",
            "f2122323fb994294972b72205efa1b9d",
            "fc7acf1db6d84cd4b3bd005a28eb7d24",
            "7b028fe12b9e43ac8515122a65a58ae3",
            "91b5be0677bf4f0ab0163d1062cd3273",
            "e46f8c4b224944f293fda62cf0b75f23",
            "506f7f5765c1473ba454f07a38345fd5",
            "d7a0e5012468456f87f486dcb4033c10",
            "70a57a9174ca43f3ba47ee971a615dab",
            "869b78264d1340dc93d978874543b024",
            "b7e8eda046504765ad0232ddb9e9ff3d",
            "dcfbb9f2b6644d11902e9925deb0a816",
            "51d1b2499e4f45e89c16860d56a60241",
            "a78fa7ea090e4eed8307ce47b9b7b6ff",
            "ba1bc238b1434538b21416feda2e3939",
            "24356d009d5942aab010b5be77b3b5ad",
            "def79dd9ed034f97a97cf7ecf8430d6a",
            "ec0c370ed80e48e49df9a7427b7ceac4",
            "a6d25551357a4eb6a53d181f4ad6a852",
            "35781a8a32244883ba3289527ae5ffb0",
            "b9b872632b5f4fc8aba151c59653608f",
            "880b078e4890449a853ff3fe7938a01a",
            "672b4f7d17d243d7a9547005fba7a054",
            "70903d12406f442fb34f11881f8e3ff6",
            "ff23d9dbdf534ffca0e9c62ece21741d",
            "baab87da64fb43cb8684db6789e36b20",
            "03607a876f5c47cabeeea780338cf759",
            "0ea7e76871244b9d92f3876ddddf1130",
            "cd2b09c581b647ac97f1ead4e00b5fe8",
            "bd437bc4209a40a19de29224490b0ef4",
            "cec61351523e4be4be10a6a8ab5e44b6",
            "5903947fa0144ae49327aeaf2f12f082"
          ]
        },
        "id": "frNuhGSDb28v",
        "outputId": "e66da9c2-24b1-47a9-a300-c21180531338"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d5e22eae172408d8f5b568880274bd1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/92 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b7e8eda046504765ad0232ddb9e9ff3d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/7 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "880b078e4890449a853ff3fe7938a01a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "main_dataset = persian_df_tr.map(formatting_prompts_function, remove_columns=persian_df_tr.column_names, batched=True)#, num_proc=1\n",
        "eval_dataset = persian_df_val.map(formatting_prompts_function, remove_columns=persian_df_val.column_names, batched=True)\n",
        "test_dataset = persian_df_te.map(formatting_prompts_function, remove_columns=persian_df_te.column_names, batched=True)\n",
        "\n",
        "main_dataset = main_dataset.shuffle(seed=seed)\n",
        "eval_dataset = eval_dataset.shuffle(seed=seed)\n",
        "test_dataset = test_dataset.shuffle(seed=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaFAUNippYMp",
        "outputId": "755db51e-0463-4098-8f18-a675c21fd887"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: line 1: os.environ[CUDA_VISIBLE_DEVICES]: command not found\n"
          ]
        }
      ],
      "source": [
        "!os.environ['CUDA_VISIBLE_DEVICES'] ='0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQvF9J1ZvS7Z"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from evaluate import load\n",
        "import numpy as np\n",
        "import math\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = logits.argmax(axis=-1)\n",
        "    labels = torch.tensor(labels, dtype=torch.int32)\n",
        "    print(\"Predictions:\", predictions.shape)\n",
        "    print(\"Labels:\", labels.shape)\n",
        "    results = {}\n",
        "    def compute_token_accuracy(predicted_ids, label_ids):\n",
        "        total_tokens = 0\n",
        "        correct_tokens = 0\n",
        "        for pred, ref in zip(predicted_ids, label_ids):\n",
        "            for p_token, r_token in zip(pred, ref):\n",
        "                if r_token != -100:\n",
        "                    total_tokens += 1\n",
        "                    if p_token == r_token:\n",
        "                        correct_tokens += 1\n",
        "        return (correct_tokens / total_tokens) * 100 if total_tokens > 0 else 0.0\n",
        "    if labels is not None:\n",
        "        logits_tensor = torch.tensor(logits, dtype=torch.float32)\n",
        "        labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
        "        per_sample_losses = []\n",
        "        for sample_logits, sample_labels in zip(logits_tensor, labels_tensor):\n",
        "            loss = F.cross_entropy(sample_logits.view(-1, sample_logits.size(-1)),sample_labels.view(-1),reduction=\"none\")\n",
        "            per_sample_loss = loss.view(sample_labels.size(0), -1).mean(dim=1).mean().item()\n",
        "            per_sample_losses.append(per_sample_loss)\n",
        "        results[\"manual_eval_loss\"] = sum(per_sample_losses) / len(per_sample_losses)\n",
        "        results[\"perplexity\"] = math.exp(results[\"manual_eval_loss\"])\n",
        "        results[\"loss_per_sample\"] = per_sample_losses\n",
        "\n",
        "    # 2. Token-Level Metrics\n",
        "    if labels is not None:\n",
        "        flattened_preds = []\n",
        "        flattened_labels = []\n",
        "        for pred, label in zip(predictions, labels):\n",
        "            for p_token, l_token in zip(pred, label):\n",
        "                if l_token != -100:\n",
        "                    flattened_preds.append(p_token)\n",
        "                    flattened_labels.append(l_token)\n",
        "\n",
        "        if flattened_labels and flattened_preds:\n",
        "            results[\"accuracy_score\"] = accuracy_score(flattened_labels, flattened_preds)\n",
        "            results[\"token_accuracy\"] = compute_token_accuracy(predictions, labels)\n",
        "            results[\"precision\"] = precision_score(flattened_labels, flattened_preds, average=\"macro\")\n",
        "            results[\"recall\"] = recall_score(flattened_labels, flattened_preds, average=\"macro\")\n",
        "            results[\"f1\"] = f1_score(flattened_labels, flattened_preds, average=\"macro\")\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8AJb-Yayxec"
      },
      "outputs": [],
      "source": [
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=main_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    dataset_num_proc=2,\n",
        "    packing=False,\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=6,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=5,\n",
        "        num_train_epochs=1,\n",
        "        learning_rate=2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        logging_strategy=\"steps\",\n",
        "        logging_steps=1,\n",
        "    ),\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YE6DjpzU7FqJ"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_zHKpZb3KzN"
      },
      "outputs": [],
      "source": [
        "eval_results = trainer.evaluate()\n",
        "print(eval_results)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}